import pandas as pd
import numpy as np
#Reading the infput/source file
df=pd.read_csv('nifty3yrdata.txt')
df.head() #Priniting top 5 rows of dataframe

DateOpenHighLowCloseShares TradedTurnover (Rs. Cr)002-Jan-20178210.108212.008133.808179.501220161115255.49103-Jan-20178196.058219.108148.608192.251311860216053.67204-Jan-20178202.658218.508180.908190.501364763456543.13305-Jan-20178226.658282.658223.708273.801639574528180.68406-Jan-20178281.858306.858233.258243.801436898507298.74
#Picking the Open stock price
df=df['Open'].values
#print(df)
print(df.shape)

(739,)

#Converting double dimension
df=df.reshape(df.size,1)
#print(df)
df.shape

(739, 1)
#Preparing training and test data sets
dataset_train=np.array(df[:int(df.shape[0]*0.8)])
print(dataset_train.shape)
dataset_test=np.array(df[int(df.shape[0]*0.8):])
print(dataset_test.shape)
#print(dataset_train)
#print(dataset_test)

(591, 1)
(148, 1)

from sklearn.preprocessing import MinMaxScaler
scalar=MinMaxScaler(feature_range=(0,1))


dataset_train=scalar.fit_transform(dataset_train)
dataset_train[:5] # Print top 5 rows of train dataset

array([[0.00379192],
       [0.        ],
       [0.00178126],
       [0.00825855],
       [0.02315633]])

dataset_test=scalar.fit_transform(dataset_test)
dataset_test[:5] # Print top 5 rows of test dataset

array([[0.66552403],
       [0.733765  ],
       [0.79905415],
       [0.76569542],
       [0.73998603]])

#Function for seperating feature and label values
def create_dataset(df):
  x=[]
  y=[]
  for i in range(df.shape[0]-1):
    x.append(df[i])
    y.append(df[i+1])
  x=np.array(x)
  y=np.array(y)
  return x,y

x_train,y_train=create_dataset(dataset_train)
x_test,y_test=create_dataset(dataset_test)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

(590, 1)
(590, 1)
(147, 1)
(147, 1)

#Reshape features for LSTM Layout
x_train=np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))
x_test=np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))
print(x_train.shape)
print(x_test.shape)

(590, 1, 1)
(147, 1, 1)

#Loading Keras functions for implementing LSTM on Keras with Tensorflow
#as backgroud
from  keras.models import Sequential, load_model
from keras.layers import LSTM, Dense, Dropout


#Training the model
model=Sequential()
model.add(LSTM(units=260,return_sequences=True,input_shape=(x_train.shape[1],1)))
model.add(Dropout(0.2))
model.add(LSTM(units=260, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=260, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=260))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(loss='mean_squared_error',optimizer='adam')

model.fit(x_train,y_train, epochs=25,batch_size=16)

Epoch 1/25
590/590 [==============================] - 8s 13ms/step - loss: 0.1410
Epoch 2/25

Epoch 24/25
590/590 [==============================] - 3s 4ms/step - loss: 0.0015
Epoch 25/25
590/590 [==============================] - 3s 4ms/step - loss: 0.0014
<keras.callbacks.History at 0x7f796e5da5f8>

#Test set
predictions=model.predict(x_test)
predictionsUnscaled=scalar.inverse_transform(predictions)
#print(predictions)
#print(predictionsUnscaled)

---------------------------------------------------------------------------------------Ignore this code - start
y_test=scalar.inverse_transform(y_test)
y_test

for i in range(x_test.shape[0]):
   print("actual value is",y_test[i], "Predicted value is -",predictionsUnscaled[i], "diff is -", y_test[i]-predictionsUnscaled[i] )

actual value is [11855.5] Predicted value is - [11767.712] diff is - [87.78808594]
actual value is [11958.35] Predicted value is - [11873.049] diff is - [85.30117188]
actual value is [11905.8] Predicted value is - [11972.845] diff is - [-67.04472656]
actual value is [11865.3] Predicted value is - [11921.981] diff is - [-56.68144531]
#function for accuracy
def accuracy(y,ycap,closeness):
  de=100-closeness
  d=abs(y-ycap)/y *100
  pcnt= d[d<=de].size
  n=y.size
  acc= pcnt/n * 100
  return acc

accuracy(predictionsUnscaled, y_test, 95)

99.31972789115646
--------------------------------- Ignore till this code - end
import matplotlib.pyplot as plt

fig, ax=plt.subplots(figsize=(16,8))

plt.plot(df, color='red', label='True Price')
ax.plot(range(len(y_train),len(y_train)+len(predictionsUnscaled)),predictionsUnscaled, color='green', label='Predicted Testing Price')
plt.legend()

 
y_test_scaled =scalar.inverse_transform(y_test.reshape(-1,1))

fig, ax=plt.subplots(figsize=(6,4))
ax.plot(y_test_scaled, color='red', label='True Testing Price')
plt.plot(predictionsUnscaled, color='green', label='Predicted Testing Price')
plt.legend()

 



import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
#Reading the infput/source file
df=pd.read_csv('nifty3yrdata.txt')
print(df.head()) #Priniting top 5 rows of dataframe
olddata=df.copy()
#olddata

def normalise(df):
  #from sklearn.preprocessing import MinMaxScaler
  scaler=MinMaxScaler(feature_range=(0,1))
  df['Open']=scaler.fit_transform(df.Open.values.reshape(-1,1))
  df['High']=scaler.fit_transform(df.High.values.reshape(-1,1))
  df['Low']=scaler.fit_transform(df.Low.values.reshape(-1,1))
  df['Close']=scaler.fit_transform(df.Close.values.reshape(-1,1))
  return df


df_scaled=normalise(df)
df_scaled.head()
df_scaled=df_scaled.drop(columns='Date')#Turnover (Rs. Cr)
df_scaled=df_scaled.drop(columns='Turnover (Rs. Cr)')
df_scaled

valid_set_size_percentage=10
test_set_size_percentage=10
seq_len=20

def load_data(stock,seq_len):
  data_raw=stock.as_matrix()
  data=[]
  # print(data_raw)
  for index in range(len(data_raw)-seq_len):
  #for index in range(100):
    #print(len(data_raw)-seq_len)
    data.append(data_raw[index:index+seq_len])
  #print(data.ndim)
  data=np.array(data)
  #print(data.ndim)
  print('data shape is:',data.shape)
  valid_set_size=int(np.round(valid_set_size_percentage/100*data.shape[0]))
  #print(valid_set_size_percentage/100*data.shape[0])
  test_set_size=int(np.round(test_set_size_percentage/100*data.shape[0]))
  #print('valid_set_size',valid_set_size)
  #print('test_set_size',test_set_size)
  train_set_size=data.shape[0]-(valid_set_size+test_set_size)
  print('train_set_size',train_set_size)
  x_train=data[:train_set_size,:-1,:]
  y_train=data[:train_set_size,-1,1]
  x_valid=data[train_set_size:train_set_size+valid_set_size,:-1,:]
  y_valid=data[train_set_size:train_set_size+valid_set_size,-1,:]
  x_test=data[train_set_size+valid_set_size:,:-1,:]
  y_test=data[train_set_size+valid_set_size:,-1,:]
  return [x_train,y_train,x_valid,y_valid,x_test,y_test]


x_train,y_train,x_valid,y_valid,x_test,y_test=load_data(df_scaled,seq_len)
print('x_train value is ',x_train.shape)
print('y_train value is ',y_train.shape)
print('x_valid value is ', x_valid.shape)
print('y_valid value is ', y_valid.shape)
print('x-test value is ', x_test.shape)
print('y_test valus is ', y_test.shape)

#Test set
predictions=model.predict(x_test)

predictionsUnscaled=scaler.inverse_transform(predictions)

y_test=scaler.inverse_transform(y_test)

for i in range(x_test.shape[0]):
   print("actual value is",y_test[i], "Predicted value is -",predictionsUnscaled[i], "diff is -", y_test[i]-predictionsUnscaled[i] )


